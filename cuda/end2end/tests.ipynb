{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates the API to register custom operator implementations for specific input and output tensor formats. This example demonstrates customization API to define new sparse tensor formats and sparsifier. It shows how to register custom operator and sparsifier implementations for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sten\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from native_scripting import compile\n",
    "import functools\n",
    "import ctypes\n",
    "import time\n",
    "import math\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cache = functools.cache\n",
    "except AttributeError:\n",
    "    cache = functools.lru_cache(maxsize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def group_n_m2(dense_shape, dense_dtype, n, m, tileM):\n",
    "    nrows = dense_shape[0]\n",
    "    ncols = dense_shape[1]\n",
    "\n",
    "    m_fixed = 4\n",
    "    A_num_cols_sp_pad = round_up((round_up(ncols, m)/m)*n, 16)\n",
    "    indexes_cols = A_num_cols_sp_pad//n*m_fixed\n",
    "\n",
    "    assert dense_dtype in (torch.float32, torch.float64)\n",
    "    dtype = \"float\" if dense_dtype == torch.float32 else \"double\"\n",
    "    lib = compile(\n",
    "        f\"\"\"\n",
    "        #include <iostream>\n",
    "        #include <algorithm>\n",
    "        #include <utility>\n",
    "        #include <cstdlib>\n",
    "        #include <cstdio>\n",
    "        #include <cmath>\n",
    "        #include <functional>\n",
    "        #include <tuple>\n",
    "        #include <vector>\n",
    "        #include <numeric>\n",
    "        #include <chrono>\n",
    "\n",
    "        using namespace std;\n",
    "\n",
    "        int int_ceil(int x, int y){{\n",
    "            return (x - 1) / y + 1;\n",
    "        }}\n",
    "\n",
    "        extern \"C\" void func({dtype}* dense, {dtype}* sparse, int* masks, int *columns){{\n",
    "            int bm_m   = {nrows}/{tileM};\n",
    "            int mcol_k = {ncols}/{m};\n",
    "            int mcol_k_p = int_ceil({ncols},{m});\n",
    "            int m_fixed = 4;\n",
    "\n",
    "            std::vector<{dtype}> v(m_fixed, 0);\n",
    "            std::vector<int> vx(m_fixed, 0);\n",
    "            {dtype} max=0, total=0;\n",
    "\n",
    "            std::vector<size_t> indices(v.size());\n",
    "            std::iota(indices.begin(), indices.end(), 0);\n",
    "\n",
    "            for(int bm_i=0; bm_i<bm_m; bm_i++){{\n",
    "                int t_bm_i   = bm_i*{tileM}*{ncols};\n",
    "                for(int mcol_i=0; mcol_i<mcol_k; mcol_i++){{\n",
    "                    int t_mcol_i = mcol_i*{m};\n",
    "                    max = 0;\n",
    "\n",
    "                    std::vector<int> cols_max;\n",
    "                    cols_max.resize(m_fixed, 0);\n",
    "                    std::vector<int> masks_max;\n",
    "                    masks_max.resize({tileM}*{m}, 0);\n",
    "\n",
    "                    for(int col_i=0; col_i<{m}; col_i++){{\n",
    "                        vx[0]=col_i;\n",
    "                        for(int col_j=col_i+1; col_j<{m}; col_j++){{\n",
    "                            vx[1]=col_j;\n",
    "                            for(int col_k=col_j+1; col_k<{m}; col_k++){{\n",
    "                                vx[2]=col_k;\n",
    "                                for(int col_w=col_k+1; col_w<{m}; col_w++){{\n",
    "                                    vx[3]=col_w;\n",
    "                                    total=0;\n",
    "\n",
    "                                    std::vector<int> mask({tileM}*{m}, 0);\n",
    "\n",
    "                                    for(int row_i=0; row_i<{tileM}; row_i++){{\n",
    "                                        int t_row_i  = row_i*{ncols};\n",
    "                                        v[0]=dense[t_bm_i + t_row_i + t_mcol_i + col_i];\n",
    "                                        v[1]=dense[t_bm_i + t_row_i + t_mcol_i + col_j];\n",
    "                                        v[2]=dense[t_bm_i + t_row_i + t_mcol_i + col_k];\n",
    "                                        v[3]=dense[t_bm_i + t_row_i + t_mcol_i + col_w];\n",
    "\n",
    "                                        std::partial_sort(indices.begin(), indices.begin() + {n}, indices.end(), [&](size_t A, size_t B) {{\n",
    "                                                    return v[A] > v[B];}});\n",
    "\n",
    "                                        for(int id=0; id<{n}; id++){{\n",
    "                                            total += dense[t_bm_i + t_row_i + t_mcol_i + vx[indices[id]]];\n",
    "\n",
    "                                            mask[row_i*{m} + vx[indices[id]]] = 1;\n",
    "                                        }}\n",
    "                                    }}\n",
    "\n",
    "                                    if(total>max){{\n",
    "                                        max = total;\n",
    "                                        std::copy(mask.begin(), mask.end(), masks_max.begin());\n",
    "\n",
    "                                        std::sort(vx.begin(), vx.begin() + m_fixed);\n",
    "                                        std::copy(vx.begin(), vx.end(), cols_max.begin());\n",
    "                                    }}\n",
    "                                }}\n",
    "                            }}\n",
    "                        }}\n",
    "                    }}\n",
    "\n",
    "                    for(int i=0; i<{tileM}; i++){{\n",
    "                        for(int j=0; j<{m}; j++){{\n",
    "                            int drop = masks_max[i*{m} + j];\n",
    "                            masks[t_bm_i  + i*{ncols}+ t_mcol_i + j]  = drop;\n",
    "                            sparse[t_bm_i + i*{ncols}+ t_mcol_i + j] *= drop;\n",
    "                        }}\n",
    "                    }}\n",
    "                    for(int i=0; i<m_fixed; i++){{\n",
    "                        columns[bm_i*{indexes_cols} + mcol_i*m_fixed + i] =\n",
    "                        cols_max[i];\n",
    "                    }}\n",
    "                }}\n",
    "            }}\n",
    "\n",
    "            int remainder = {ncols}%{m};\n",
    "\n",
    "            if (remainder>0){{\n",
    "                int d_rows={tileM}, d_cols=remainder;\n",
    "\n",
    "                if(remainder<3){{\n",
    "                    for(int i=0; i<{nrows}; i++){{\n",
    "                        for(int j={ncols}-remainder; j<{ncols}; j++){{\n",
    "                            masks[i*{ncols}+j] = 1;\n",
    "                        }}\n",
    "                    }}\n",
    "                    for(int bm_i=0; bm_i<bm_m; bm_i++){{\n",
    "                        for(int j=0; j<m_fixed; j++){{\n",
    "                            columns[bm_i*{indexes_cols} + mcol_k*m_fixed + j] = j;\n",
    "                        }}\n",
    "                    }}\n",
    "                }} else if(remainder==3){{\n",
    "                    v[3] = -1;\n",
    "                    for(int bm_i=0; bm_i<bm_m; bm_i++){{\n",
    "                        int t_bm_i   = bm_i*{tileM}*{ncols};\n",
    "                        for(int mcol_i=mcol_k; mcol_i<mcol_k_p; mcol_i++){{\n",
    "                            max = 0;\n",
    "                            int t_mcol_i = mcol_i*{m};\n",
    "\n",
    "                            std::vector<int> cols_max(m_fixed, 0);\n",
    "                            std::vector<int> masks_max({tileM}*remainder, 0);\n",
    "\n",
    "                            for(int col_i=0; col_i<remainder; col_i++){{\n",
    "                                vx[0]=col_i;\n",
    "                                for(int col_j=col_i+1; col_j<remainder; col_j++){{\n",
    "                                    vx[1]=col_j;\n",
    "                                    for(int col_k=col_j+1; col_k<remainder; col_k++){{\n",
    "                                        vx[2]=col_k;\n",
    "                                        total=0;\n",
    "                                        std::vector<int> mask({tileM}*remainder, 0);\n",
    "\n",
    "                                        for(int row_i=0; row_i<{tileM}; row_i++){{\n",
    "                                            int t_row_i  = row_i*{ncols};\n",
    "                                            v[0]=dense[t_bm_i + t_row_i + t_mcol_i + col_i];\n",
    "                                            v[1]=dense[t_bm_i + t_row_i + t_mcol_i + col_j];\n",
    "                                            v[2]=dense[t_bm_i + t_row_i + t_mcol_i + col_k];\n",
    "\n",
    "                                            std::partial_sort(indices.begin(), indices.begin() + {n}, indices.end(), [&](size_t A, size_t B) {{\n",
    "                                                        return v[A] > v[B]; }});\n",
    "\n",
    "                                            for(int id=0; id<{n}; id++){{\n",
    "                                                total += dense[t_bm_i + t_row_i + t_mcol_i + vx[indices[id]]];\n",
    "\n",
    "                                                mask[row_i*remainder + vx[indices[id]]] = 1;\n",
    "                                            }}\n",
    "                                        }}\n",
    "\n",
    "                                        if(total>max){{\n",
    "                                            max = total;\n",
    "                                            std::copy(mask.begin(), mask.end(), masks_max.begin());\n",
    "\n",
    "                                            std::sort(vx.begin(), vx.begin() + remainder);//m_fixed\n",
    "                                            std::copy(vx.begin(), vx.end(), cols_max.begin());\n",
    "                                        }}\n",
    "                                    }}\n",
    "                                }}\n",
    "                            }}\n",
    "\n",
    "                            for(int i=0; i<{tileM}; i++){{\n",
    "                                for(int j=0; j<remainder; j++){{\n",
    "                                    int drop = masks_max[i*remainder + j];\n",
    "\n",
    "                                    masks[t_bm_i  + i*{ncols}+ t_mcol_i + j]  = drop;\n",
    "                                    sparse[t_bm_i + i*{ncols}+ t_mcol_i + j] *= drop;\n",
    "                                }}\n",
    "                            }}\n",
    "                            for(int i=0; i<remainder; i++){{\n",
    "                                columns[bm_i*{indexes_cols} + mcol_i*m_fixed + i] =\n",
    "                                cols_max[i];\n",
    "                            }}\n",
    "                        }}\n",
    "                    }}\n",
    "                }} else {{\n",
    "                    for(int bm_i=0; bm_i<bm_m; bm_i++){{\n",
    "                        int t_bm_i   = bm_i*{tileM}*{ncols};\n",
    "                        for(int mcol_i=mcol_k; mcol_i<mcol_k_p; mcol_i++){{\n",
    "                            max = 0;\n",
    "                            int t_mcol_i = mcol_i*{m};\n",
    "\n",
    "                            std::vector<int> cols_max(m_fixed, 0);\n",
    "                            std::vector<int> masks_max({tileM}*remainder, 0);\n",
    "\n",
    "                            for(int col_i=0; col_i<remainder; col_i++){{\n",
    "                                vx[0]=col_i;\n",
    "                                for(int col_j=col_i+1; col_j<remainder; col_j++){{\n",
    "                                    vx[1]=col_j;\n",
    "                                    for(int col_k=col_j+1; col_k<remainder; col_k++){{\n",
    "                                        vx[2]=col_k;\n",
    "                                        for(int col_w=col_k+1; col_w<remainder; col_w++){{\n",
    "                                            vx[3]=col_w;\n",
    "                                            total=0;\n",
    "                                            std::vector<int> mask({tileM}*remainder, 0);\n",
    "\n",
    "                                            for(int row_i=0; row_i<{tileM}; row_i++){{\n",
    "                                                int t_row_i  = row_i*{ncols};\n",
    "                                                v[0]=dense[t_bm_i + t_row_i + t_mcol_i + col_i];\n",
    "                                                v[1]=dense[t_bm_i + t_row_i + t_mcol_i + col_j];\n",
    "                                                v[2]=dense[t_bm_i + t_row_i + t_mcol_i + col_k];\n",
    "                                                v[3]=dense[t_bm_i + t_row_i + t_mcol_i + col_w];\n",
    "\n",
    "                                                std::partial_sort(indices.begin(), indices.begin() + {n}, indices.end(), [&](size_t A, size_t B) {{\n",
    "                                                            return v[A] > v[B]; }});\n",
    "\n",
    "                                                for(int id=0; id<{n}; id++){{\n",
    "                                                    total += dense[t_bm_i + t_row_i + t_mcol_i + vx[indices[id]]];\n",
    "\n",
    "                                                    mask[row_i*remainder + vx[indices[id]]] = 1;\n",
    "                                                }}\n",
    "                                            }}\n",
    "\n",
    "                                            if(total>max){{\n",
    "                                                max = total;\n",
    "                                                std::copy(mask.begin(), mask.end(), masks_max.begin());\n",
    "\n",
    "                                                std::sort(vx.begin(), vx.begin() + m_fixed);\n",
    "                                                std::copy(vx.begin(), vx.end(), cols_max.begin());\n",
    "                                            }}\n",
    "                                        }}\n",
    "                                    }}\n",
    "                                }}\n",
    "                            }}\n",
    "\n",
    "                            for(int i=0; i<{tileM}; i++){{\n",
    "                                for(int j=0; j<remainder; j++){{\n",
    "                                    int drop = masks_max[i*remainder + j];\n",
    "\n",
    "                                    masks[t_bm_i  + i*{ncols}+ t_mcol_i + j]  = drop;\n",
    "                                    sparse[t_bm_i + i*{ncols}+ t_mcol_i + j] *= drop;\n",
    "                                }}\n",
    "                            }}\n",
    "                            for(int i=0; i<m_fixed; i++){{\n",
    "                                columns[bm_i*{indexes_cols} + mcol_i*m_fixed + i] =\n",
    "                                cols_max[i];\n",
    "                            }}\n",
    "                        }}\n",
    "                    }}\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "        \"\"\",\n",
    "    )\n",
    "    lib.func.argtypes = [\n",
    "        ctypes.c_void_p,\n",
    "        ctypes.c_void_p,\n",
    "        ctypes.c_void_p,\n",
    "        ctypes.c_void_p,\n",
    "    ]\n",
    "    return lib.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def to_dense(dense_shape, dense_dtype, n, m, tileM):\n",
    "    nrows = dense_shape[0]\n",
    "    ncols = dense_shape[1]\n",
    "\n",
    "    A_size = nrows*ncols\n",
    "    density = n/m\n",
    "\n",
    "    brow = 4 #this->brow = brow_;\n",
    "    mbrow = 32 #this->mbrow = mbrow_;\n",
    "\n",
    "    bm   = tileM\n",
    "    # !IMPORTANT! constants because of architecture constraints\n",
    "    m_fixed = 4\n",
    "    bits_elem_meta=2\n",
    "    mrow_m = 2\n",
    "    bits_elem_cols=8\n",
    "    brow_fixed = 16\n",
    "    nelems=32//bits_elem_meta #(sizeof(uint)*8)=32\n",
    "    nelems_col = nelems//mrow_m\n",
    "\n",
    "    A_num_cols_sp = (ncols/m)*n\n",
    "    A_num_cols_sp_pad_nm = (round_up(ncols, m)/m)*n\n",
    "    A_num_cols_sp_pad = round_up((round_up(ncols, m)/m)*n, 16)\n",
    "    A_nnz = nrows*A_num_cols_sp_pad\n",
    "\n",
    "    assert dense_dtype in (torch.float32, torch.float64)\n",
    "    dtype = \"float\" if dense_dtype == torch.float32 else \"double\"\n",
    "    lib = compile(\n",
    "        f\"\"\"\n",
    "        #include <iostream>\n",
    "        #include <algorithm>\n",
    "        #include <utility>\n",
    "        #include <cstdlib>\n",
    "        #include <cstdio>\n",
    "        #include <cmath>\n",
    "        #include <functional>\n",
    "        #include <tuple>\n",
    "        #include <vector>\n",
    "        #include <numeric>\n",
    "        #include <chrono>\n",
    "\n",
    "        using namespace std;\n",
    "\n",
    "\n",
    "        extern \"C\" void func3({dtype}* hA_dense, {dtype}* hA_values, int *hA_columns, int *hA_metadata){{\n",
    "            //this->hA_dense.resize(this->A_size, 0);\n",
    "\n",
    "            // general variables N:M format\n",
    "            int bm_m = {nrows}/{bm};\n",
    "            int mbrow_m = {bm}/{mbrow};\n",
    "            int mbrow_m2 = {mbrow}/{brow_fixed};\n",
    "            int brow_m = {brow_fixed}/{brow};\n",
    "            // metadata\n",
    "            int mcol_kk = {nelems}/{mrow_m}/{n};\n",
    "            int mcol_k = {A_num_cols_sp_pad}/{n}/mcol_kk;\n",
    "            // indices\n",
    "            int col_kk = mcol_kk;\n",
    "            int col_k = {A_num_cols_sp_pad}/{n}/col_kk;\n",
    "\n",
    "            uint indexes[{nelems}];\n",
    "            uint columns[col_kk*{m_fixed}];\n",
    "\n",
    "            for(int bm_i=0; bm_i<bm_m; bm_i++){{\n",
    "                for(int mbrow_i=0; mbrow_i<mbrow_m; mbrow_i++){{\n",
    "                    for(int mbrow_i2=0; mbrow_i2<mbrow_m2; mbrow_i2++){{\n",
    "                        for(int brow_i=0; brow_i<brow_m; brow_i++){{\n",
    "                            for(int mcol_i=0; mcol_i<mcol_k; mcol_i++){{\n",
    "                                //read columns indexes\n",
    "                                for(int col_i=0; col_i<col_kk; col_i++){{\n",
    "                                    for(int col_ii=0; col_ii<{m_fixed}; col_ii++){{\n",
    "                                        columns[col_i*{m_fixed} + col_ii] =\n",
    "                                        hA_columns[bm_i*col_k*col_kk*{m_fixed} + mcol_i*col_kk*{m_fixed} + col_i*{m_fixed} + col_ii];\n",
    "                                    }}\n",
    "                                }}\n",
    "                                // read metadata\n",
    "                                for(int mbrow_ii=0; mbrow_ii<({brow}/{mrow_m}); mbrow_ii++){{\n",
    "                                    for(int mbrow_iii=0; mbrow_iii<{mrow_m}; mbrow_iii++){{\n",
    "                                        for(int mcol_ii=0; mcol_ii<mcol_kk; mcol_ii++){{\n",
    "                                            for (int n_i=0; n_i<{n}; n_i++) {{\n",
    "                                                indexes[\n",
    "                                                    mbrow_iii*{n} +\n",
    "                                                    mcol_ii*{mrow_m}*{n} +\n",
    "                                                    n_i] =\n",
    "                                                (((hA_metadata[\n",
    "                                                    bm_i*mcol_k*{bm}/{mrow_m} +\n",
    "                                                    mbrow_i*mcol_k*{mbrow}/{mrow_m} +\n",
    "                                                    mbrow_i2*{brow_fixed}/{mrow_m} +\n",
    "                                                    brow_i*{brow}/{mrow_m}  +\n",
    "                                                    mcol_i*{mbrow}/{mrow_m} +\n",
    "                                                    mbrow_ii]) >> (mbrow_iii*({nelems}/{mrow_m})*{bits_elem_meta}+mcol_ii*{n}*{bits_elem_meta}+n_i*{bits_elem_meta})) & 0x3);\n",
    "                                            }}\n",
    "                                        }}\n",
    "                                    }}\n",
    "\n",
    "                                    for(int mcol_ii=0; mcol_ii<mcol_kk; mcol_ii++){{\n",
    "                                        for(int mbrow_iii=0; mbrow_iii<{mrow_m}; mbrow_iii++){{\n",
    "                                            for(int n_i=0; n_i<{n}; n_i++){{\n",
    "                                                unsigned int index = columns[mcol_ii*{m_fixed} + indexes[mcol_ii*{mrow_m}*{n}+mbrow_iii*{n}+n_i]];\n",
    "\n",
    "                                                if((mcol_i*{m}*mcol_kk + mcol_ii*{m} + index) < {ncols}){{\n",
    "                                                    hA_dense[\n",
    "                                                        bm_i*{bm}*{ncols} +\n",
    "                                                        mbrow_i*{mbrow}*{ncols} +\n",
    "                                                        mbrow_i2*{brow_fixed}*{ncols} +\n",
    "                                                        brow_i*{brow}*{ncols} +\n",
    "                                                        mcol_i*{m}*mcol_kk +\n",
    "                                                        mbrow_ii*{mrow_m}*{ncols} +\n",
    "                                                        mcol_ii*{m} +\n",
    "                                                        mbrow_iii*{ncols} +\n",
    "                                                        index] =\n",
    "                                                    hA_values[\n",
    "                                                        bm_i*{bm}*{A_num_cols_sp_pad} +\n",
    "                                                        mbrow_i*{mbrow}*{A_num_cols_sp_pad}+\n",
    "                                                        mbrow_i2*{brow_fixed}*{A_num_cols_sp_pad}+\n",
    "                                                        brow_i*{brow}*{nelems}/{mrow_m}+\n",
    "                                                        mcol_i*{brow_fixed}*{nelems}/{mrow_m} +\n",
    "                                                        mbrow_ii*{mrow_m}*{n} +\n",
    "                                                        mcol_ii*{n}*{brow} +\n",
    "                                                        mbrow_iii*{n} +\n",
    "                                                        n_i];\n",
    "                                                }}\n",
    "                                            }}\n",
    "                                        }}\n",
    "                                    }}\n",
    "                                }}\n",
    "                            }}\n",
    "                        }}\n",
    "                    }}\n",
    "                }}\n",
    "            }}\n",
    "        }}\n",
    "        \"\"\",\n",
    "    )\n",
    "    lib.func3.argtypes = [\n",
    "        ctypes.c_void_p,\n",
    "        ctypes.c_void_p,\n",
    "        ctypes.c_void_p,\n",
    "        ctypes.c_void_p,\n",
    "    ]\n",
    "    return lib.func3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def to_sparse_sr_nm(dense_shape, dense_dtype, n, m, tileM):\n",
    "    nrows = dense_shape[0]\n",
    "    ncols = dense_shape[1]\n",
    "\n",
    "    brow = 4 #this->brow = brow_;\n",
    "    mbrow = 32 #this->mbrow = mbrow_;\n",
    "\n",
    "    bm   = tileM\n",
    "    # !IMPORTANT! constants because of architecture constraints\n",
    "    m_fixed = 4\n",
    "    bits_elem_meta=2\n",
    "    mrow_m = 2\n",
    "    bits_elem_cols=8\n",
    "    brow_fixed = 16\n",
    "    nelems=32//bits_elem_meta #(sizeof(uint)*8)=32\n",
    "    nelems_col = nelems//mrow_m\n",
    "\n",
    "    A_num_cols_sp = (ncols//m)*n\n",
    "    A_num_cols_sp_pad_nm = (round_up(ncols, m)/m)*n\n",
    "    A_num_cols_sp_pad = round_up((round_up(ncols, m)/m)*n, 16)\n",
    "    A_nnz = nrows*A_num_cols_sp_pad\n",
    "\n",
    "    assert dense_dtype in (torch.float32, torch.float64)\n",
    "    dtype = \"float\" if dense_dtype == torch.float32 else \"double\"\n",
    "    lib = compile(\n",
    "        f\"\"\"\n",
    "        #include <iostream>\n",
    "        #include <algorithm>\n",
    "        #include <utility>\n",
    "        #include <cstdlib>\n",
    "        #include <cstdio>\n",
    "        #include <cmath>\n",
    "        #include <functional>\n",
    "        #include <tuple>\n",
    "        #include <vector>\n",
    "        #include <numeric>\n",
    "        #include <chrono>\n",
    "\n",
    "        using namespace std;\n",
    "\n",
    "\n",
    "        extern \"C\" void func2({dtype}* sparse, int* masks, {dtype}* hA_values, int *hA_columns, int *hA_metadata){{\n",
    "\n",
    "            int bm_m = {nrows}/{bm};\n",
    "            int mbrow_m = {bm}/{mbrow};\n",
    "            int mbrow_m2 = {mbrow}/{brow_fixed};\n",
    "            int brow_m = {brow_fixed}/{brow};\n",
    "            // metadata\n",
    "            int mcol_kk = {nelems}/{mrow_m}/{n};\n",
    "            int mcol_k = {A_num_cols_sp_pad}/{n}/mcol_kk;\n",
    "            // indices\n",
    "            int col_kk = mcol_kk;\n",
    "            int col_k = {A_num_cols_sp_pad}/{n}/col_kk;\n",
    "\n",
    "            {dtype} values[{nelems}];\n",
    "            uint indexes[{nelems}];\n",
    "            uint columns[col_kk*{m_fixed}];\n",
    "\n",
    "            int max_idx = 0;\n",
    "\n",
    "            for(int bm_i=0; bm_i<bm_m; bm_i++){{\n",
    "                for(int mbrow_i=0; mbrow_i<mbrow_m; mbrow_i++){{\n",
    "                    for(int mbrow_i2=0; mbrow_i2<mbrow_m2; mbrow_i2++){{\n",
    "                        for(int brow_i=0; brow_i<brow_m; brow_i++){{\n",
    "                            for(int mcol_i=0; mcol_i<mcol_k; mcol_i++){{\n",
    "                                for(int col_i=0; col_i<col_kk; col_i++){{\n",
    "                                    for(int col_ii=0; col_ii<{m_fixed}; col_ii++){{\n",
    "                                        columns[col_i*{m_fixed} + col_ii] =\n",
    "                                        hA_columns[bm_i*col_k*col_kk*{m_fixed} + mcol_i*col_kk*{m_fixed} + col_i*{m_fixed} + col_ii];\n",
    "                                    }}\n",
    "                                }}\n",
    "                                for(int mbrow_ii=0; mbrow_ii<({brow}/{mrow_m}); mbrow_ii++){{\n",
    "                                    for(int mcol_ii=0; mcol_ii<mcol_kk; mcol_ii++){{\n",
    "                                        for(int mbrow_iii=0; mbrow_iii<{mrow_m}; mbrow_iii++){{\n",
    "                                            int pos=0;\n",
    "                                            for(int n_i=0; n_i<{m_fixed}; n_i++){{\n",
    "                                                unsigned int index = columns[mcol_ii*{m_fixed} + n_i];\n",
    "\n",
    "                                                if((mcol_i*{m}*mcol_kk + mcol_ii*{m} + index) < {ncols}){{\n",
    "                                                    int nnz = masks[\n",
    "                                                            bm_i*{bm}*{ncols} +\n",
    "                                                            mbrow_i*{mbrow}*{ncols} +\n",
    "                                                            mbrow_i2*{brow_fixed}*{ncols} +\n",
    "                                                            brow_i*{brow}*{ncols} +\n",
    "                                                            mcol_i*{m}*mcol_kk +\n",
    "                                                            mbrow_ii*{mrow_m}*{ncols} +\n",
    "                                                            mcol_ii*{m} +\n",
    "                                                            mbrow_iii*{ncols} +\n",
    "                                                            index];\n",
    "\n",
    "                                                    if(nnz != 0){{\n",
    "                                                        indexes[\n",
    "                                                            mbrow_iii*{n} +\n",
    "                                                            mcol_ii*{mrow_m}*{n} +\n",
    "                                                            pos] = n_i;\n",
    "\n",
    "                                                        values[\n",
    "                                                            mcol_ii*{mrow_m}*{n} +\n",
    "                                                            mbrow_iii*{n} +\n",
    "                                                            pos] =\n",
    "                                                        sparse[\n",
    "                                                            bm_i*{bm}*{ncols} +\n",
    "                                                            mbrow_i*{mbrow}*{ncols} +\n",
    "                                                            mbrow_i2*{brow_fixed}*{ncols} +\n",
    "                                                            brow_i*{brow}*{ncols} +\n",
    "                                                            mcol_i*{m}*mcol_kk +\n",
    "                                                            mbrow_ii*{mrow_m}*{ncols} +\n",
    "                                                            mcol_ii*{m} +\n",
    "                                                            mbrow_iii*{ncols} +\n",
    "                                                            index];\n",
    "\n",
    "                                                        pos+=1;\n",
    "                                                    }}\n",
    "                                                }} else {{\n",
    "                                                    if(n_i<2){{\n",
    "                                                        indexes[\n",
    "                                                            mbrow_iii*{n} +\n",
    "                                                            mcol_ii*{mrow_m}*{n} +\n",
    "                                                            pos] = 0;\n",
    "\n",
    "                                                        values[\n",
    "                                                            mcol_ii*{mrow_m}*{n} +\n",
    "                                                            mbrow_iii*{n} +\n",
    "                                                            pos] = 0;\n",
    "\n",
    "                                                        pos+=1;\n",
    "                                                    }}\n",
    "                                                }}\n",
    "                                            }}\n",
    "                                        }}\n",
    "                                    }}\n",
    "                                    // write metadata\n",
    "                                    unsigned int meta=0;\n",
    "                                    for(int mbrow_iii=0; mbrow_iii<{mrow_m}; mbrow_iii++){{\n",
    "                                        for(int mcol_ii=0; mcol_ii<mcol_kk; mcol_ii++){{\n",
    "                                            for (int n_i=0; n_i<{n}; n_i++) {{\n",
    "\n",
    "                                                int idx = bm_i*{bm}*{A_num_cols_sp_pad} +\n",
    "                                                        mbrow_i*{mbrow}*{A_num_cols_sp_pad}+\n",
    "                                                        mbrow_i2*{brow_fixed}*{A_num_cols_sp_pad}+\n",
    "                                                        brow_i*{brow}*{nelems}/{mrow_m}+\n",
    "                                                        mcol_i*{brow_fixed}*{nelems}/{mrow_m} +\n",
    "                                                        mbrow_ii*{mrow_m}*{n} +\n",
    "                                                        mcol_ii*{n}*{brow} +\n",
    "                                                        mbrow_iii*{n} +\n",
    "                                                        n_i;\n",
    "\n",
    "                                                max_idx = (idx>max_idx)?(idx):(max_idx);\n",
    "\n",
    "                                                hA_values[\n",
    "                                                        idx] =\n",
    "                                                values[\n",
    "                                                    mcol_ii*{mrow_m}*{n} +\n",
    "                                                    mbrow_iii*{n} +\n",
    "                                                    n_i];\n",
    "\n",
    "                                                unsigned int tmp = indexes[\n",
    "                                                            mbrow_iii*{n} +\n",
    "                                                            mcol_ii*{mrow_m}*{n} +\n",
    "                                                            n_i];\n",
    "                                                meta |= (tmp << (mbrow_iii*({nelems}/{mrow_m})*{bits_elem_meta}+mcol_ii*{n}*{bits_elem_meta}+n_i*{bits_elem_meta}));\n",
    "                                            }}\n",
    "                                        }}\n",
    "                                    }}\n",
    "                                    hA_metadata[bm_i*mcol_k*{bm}/{mrow_m} +\n",
    "                                                mbrow_i*mcol_k*{mbrow}/{mrow_m} +\n",
    "                                                mbrow_i2*{brow_fixed}/{mrow_m} +\n",
    "                                                brow_i*{brow}/{mrow_m}  +\n",
    "                                                mcol_i*{mbrow}/{mrow_m} +\n",
    "                                                mbrow_ii] = meta;\n",
    "                                }}\n",
    "                            }}\n",
    "                        }}\n",
    "                    }}\n",
    "                }}\n",
    "            }}\n",
    "            cout << \"max_idx: \" << max_idx << endl;\n",
    "        }}\n",
    "        \"\"\",\n",
    "    )\n",
    "    lib.func2.argtypes = [\n",
    "        ctypes.c_void_p,\n",
    "        ctypes.c_void_p,\n",
    "        ctypes.c_void_p,\n",
    "        ctypes.c_void_p,\n",
    "        ctypes.c_void_p,\n",
    "    ]\n",
    "    return lib.func2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_up(x,y):\n",
    "    return math.ceil(x/y)*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(768, 768, requires_grad=True)\n",
    "b = torch.randn(768, 768, requires_grad=True)\n",
    "#b = torch.ones(64, 64, requires_grad=True)\n",
    "c = torch.ones(768, 768, requires_grad=True)\n",
    "grad_d = torch.randn(768, 768)\n",
    "\n",
    "d = torch.mm(torch.add(a, b), c)\n",
    "d.backward(grad_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SrNMTensor:\n",
    "    def __init__(self, n_, m_, tileM_, dense_, mask_, columns_):\n",
    "        self.n = n_\n",
    "        self.m = m_\n",
    "        self.tileM = tileM_\n",
    "        self.nnz = 0\n",
    "        self.nrows = None\n",
    "        self.ncols = None\n",
    "        #self.dense = dense_\n",
    "        #self.mask = mask_\n",
    "        self.columns = columns_        \n",
    "        self.data = None\n",
    "        self.metadata = None       \n",
    "        self.to_sparse_sr_nm(dense_, mask_) \n",
    "        #self.dense = None\n",
    "    \n",
    "    def to_sparse_sr_nm(self, dense_, mask_):\n",
    "        impl_builder = (\n",
    "            to_sparse_sr_nm\n",
    "            )\n",
    "        func = impl_builder(\n",
    "                dense_.shape,\n",
    "                dense_.dtype,\n",
    "                self.n,\n",
    "                self.m,\n",
    "                self.tileM\n",
    "            )\n",
    "        \n",
    "        self.nrows, self.ncols = dense_.shape\n",
    "        A_num_cols_sp_pad = round_up((round_up(self.ncols, self.m)/self.m)*self.n, 16)\n",
    "        self.nnz = self.nrows*A_num_cols_sp_pad\n",
    "        m_fixed = 4\n",
    "        mrow_m = 2\n",
    "        bits_elem_meta=2\n",
    "\n",
    "        nelems = 32//bits_elem_meta #32=(sizeof(uint)*8)\n",
    "        nelems_col = nelems//mrow_m\n",
    "\n",
    "        self.values = torch.zeros(self.nrows * A_num_cols_sp_pad, dtype=dense_.dtype)\n",
    "        self.metadata = torch.zeros(self.nrows//mrow_m * A_num_cols_sp_pad//nelems_col, dtype=torch.int32)\n",
    "\n",
    "        func(dense_.data_ptr(), mask_.data_ptr(), self.values.data_ptr(), self.columns.data_ptr(), self.metadata.data_ptr())     \n",
    "\n",
    "    def to_dense(self):\n",
    "        impl_builder = (\n",
    "            to_dense\n",
    "            )\n",
    "        func = impl_builder(\n",
    "                (self.nrows, self.ncols),\n",
    "                self.values.dtype,\n",
    "                self.n,\n",
    "                self.m,\n",
    "                self.tileM\n",
    "            )\n",
    "        dense = torch.zeros((self.nrows, self.ncols), dtype=self.values.dtype)\n",
    "        func(dense.data_ptr(), self.values.data_ptr(), self.columns.data_ptr(), self.metadata.data_ptr())\n",
    "\n",
    "        return dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMVectorSparsifier:\n",
    "    def __init__(self, n, m, tileM):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.tileM = tileM\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nm_vector_mask_sparsify(tensor, n, m, tileM):\n",
    "    print(\"nm_vector_mask_sparsify\", n, m, tileM)\n",
    "\n",
    "    impl_builder = (\n",
    "                group_n_m2\n",
    "                )\n",
    "    nrows, ncols = tensor.shape\n",
    "    A_num_cols_sp_pad = round_up((round_up(ncols, m)/m)*n, 16)            \n",
    "    bm_m   = nrows//tileM\n",
    "    mcol_k_p = math.ceil(ncols/m)\n",
    "    m_fixed = 4\n",
    "    \n",
    "    # Structures represent sparse data\n",
    "    masks = torch.zeros(tensor.shape, dtype=torch.int32)    \n",
    "    columns = torch.zeros(nrows//tileM * A_num_cols_sp_pad//n*m_fixed,dtype=torch.int32)\n",
    "    if len(tensor.shape) == 2:\n",
    "        tensor_temp = tensor.cpu().detach().abs()\n",
    "        sparse = tensor_temp.clone()        \n",
    "\n",
    "        func = impl_builder(\n",
    "                    tensor_temp.shape,\n",
    "                    tensor_temp.dtype,\n",
    "                    n,\n",
    "                    m,\n",
    "                    tileM\n",
    "                )\n",
    "        func(tensor_temp.data_ptr(), sparse.data_ptr(), masks.data_ptr(), columns.data_ptr())\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only support layers of dimension 2 or 4\")\n",
    "\n",
    "    #self.columns = columns\n",
    "    #return masks\n",
    "    return masks, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sten.register_sparsifier_implementation(\n",
    "    sparsifier=NMVectorSparsifier, inp=torch.Tensor, out=SrNMTensor\n",
    ")\n",
    "def torch_tensor_to_srnm_random_fraction(sparsifier, tensor, grad_fmt=None):\n",
    "    print(\"inside NMVectorSparsifier sparsifier\")\n",
    "    masks, columns = nm_vector_mask_sparsify(tensor, sparsifier.n, sparsifier.m, sparsifier.tileM)\n",
    "    return sten.SparseTensorWrapper.wrapped_from_dense(\n",
    "        SrNMTensor(sparsifier.n, sparsifier.m, sparsifier.tileM, tensor, masks, columns),\n",
    "        tensor,\n",
    "        grad_fmt,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2; m=4; tileM=128\n",
    "BM=32\n",
    "BN=32\n",
    "BK=32\n",
    "WM=32\n",
    "WN=32\n",
    "WK=32\n",
    "MM=16\n",
    "MN=8\n",
    "MK=32\n",
    "NSTAGE=2\n",
    "\n",
    "sparse_add = sten.sparsified_op(\n",
    "    orig_op=torch.add,\n",
    "    out_fmt=(\n",
    "        (sten.KeepAll(), torch.Tensor,\n",
    "         NMVectorSparsifier(n,m,tileM), SrNMTensor),\n",
    "    ),\n",
    "    grad_out_fmt=(\n",
    "        (sten.KeepAll(), torch.Tensor,\n",
    "         NMVectorSparsifier(n,m,tileM), SrNMTensor),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.add(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we try to use the operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srnm = sparse_add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srnm.wrapped_tensor.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( torch.equal(srnm.wrapped_tensor.to_dense(), torch.add(a, b)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( srnm.wrapped_tensor.values.cuda() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spatha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sten.register_fwd_op_impl(\n",
    "    operator=torch.mm,\n",
    "    inp=(SrNMTensor, torch.Tensor),\n",
    "    out=[(sten.KeepAll, torch.Tensor)],\n",
    ")\n",
    "def sparse_torch_add_fwd_impl(ctx, inputs, output_sparsifiers):\n",
    "    \"\"\" input, other = inputs\n",
    "    [out_sp] = output_sparsifiers\n",
    "    dense_out = torch.add(\n",
    "        input.wrapped_tensor.to_dense(),\n",
    "        other.wrapped_tensor.to_dense(),\n",
    "    )\n",
    "    return torch_tensor_to_srnm_random_fraction(\n",
    "        KeepAll(), nm_vector_mask_sparsify(dense_out, out_sp.n, out_sp.m, out_sp.tileM)\n",
    "    ) \"\"\"\n",
    "\n",
    "    input1, input2 = inputs\n",
    "    ctx.save_for_backward(input1, input2)\n",
    "    #output = torch.from_numpy(input1.wrapped_tensor.data @ input2.numpy())\n",
    "    \n",
    "    #bias = torch.zeros((input1.wrapped_tensor.nrows, input2.shape[1]))\n",
    "    bias = torch.ones(input1.wrapped_tensor.nrows)*2\n",
    "    output = spatha.spmm(input1.wrapped_tensor.metadata.cuda(), # metadata\n",
    "                          input1.wrapped_tensor.columns.cuda(),  # indices\n",
    "                          input1.wrapped_tensor.values.to(dtype=torch.half).cuda(),                                    # values\n",
    "                          input2.to(dtype=torch.half).cuda(),    # rhs_matrix\n",
    "                          bias.to(dtype=torch.half).cuda(),\n",
    "                          input1.wrapped_tensor.nrows,           # A_num_rows\n",
    "                          input1.wrapped_tensor.ncols,           # A_num_cols\n",
    "                          input2.shape[1],                       # B_num_cols\n",
    "                          input1.wrapped_tensor.tileM,           # vec_length\n",
    "                          input1.wrapped_tensor.n,               # n\n",
    "                          input1.wrapped_tensor.m,               # m\n",
    "                          input1.wrapped_tensor.nnz,             # nnz\n",
    "                          0,                                     # seed\n",
    "                          32,                                    # mbrow\n",
    "                          4                                     # brow\n",
    "                          )\n",
    "    return output\n",
    "\n",
    "#a1 = sparse_add(a, b).to(dtype=torch.half).to(device=\"cuda:0\")\n",
    "#c = c.to(dtype=torch.half).to(device=\"cuda:0\")\n",
    "\n",
    "d = torch.mm(sparse_add(a, b), c)\n",
    "\n",
    "#print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.from_numpy(srnm.wrapped_tensor.to_dense().to(dtype=torch.half).detach().numpy() @ c.detach().numpy()).to(device=\"cuda:0\").to(dtype=torch.half)\n",
    "#e = torch.from_numpy(a.detach().numpy() @ c.detach().numpy()).to(device=\"cuda:0\")\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = torch.ones((e.shape))*2\n",
    "e+=bias.to(dtype=torch.half).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( torch.equal(d.T,e) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( torch.allclose(d.T,e) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.any(d.T != e, axis=1).nonzero().flatten()\n",
    "print(d.T[1])\n",
    "print(e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aaabd9c823c2fe20b83f6b6df33c59a086e7b4feb3f85a53e501867b69c10504"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
